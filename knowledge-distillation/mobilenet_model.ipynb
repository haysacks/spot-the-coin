{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenet_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vev5DAYLK5OZ",
        "colab_type": "text"
      },
      "source": [
        "# **Bangkit Final Project: World Coin Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aF2mIOQNC5o",
        "colab_type": "text"
      },
      "source": [
        "# **Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu8dZbIdLrLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.models import Sequential, Model, model_from_json\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, LeakyReLU\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import Regularizer, l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "from google.colab import files, drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0MskslwLsYt",
        "colab_type": "code",
        "outputId": "da341412-dc62-4f55-9ed8-58e20d14f101",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Upload the kaggle.json file from Kaggle account settings page\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9ba4c998-8f06-48d8-9335-0fd14f2691ab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9ba4c998-8f06-48d8-9335-0fd14f2691ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH-mZ_XHMezh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the Kaggle API client\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdSwixL0MUxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo_rjYl-NU0_",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS2VsR0CNg0G",
        "colab_type": "code",
        "outputId": "5c50bf00-6589-4574-e8a2-c485fb59859d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Download the dataset\n",
        "!kaggle datasets download -d wanderdust/coin-images"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading coin-images.zip to /content\n",
            " 98% 451M/459M [00:04<00:00, 107MB/s]\n",
            "100% 459M/459M [00:04<00:00, 102MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN_bT4N7OopU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If kaggle is down, mount from drive\n",
        "try:\n",
        "    coin_file = open('/content/coin-images.zip', 'r')\n",
        "    filepath = '/content/coin-images.zip'\n",
        "except FileNotFoundError:\n",
        "    # Keep preset values\n",
        "    drive.mount('/content/drive')\n",
        "    filepath = '/content/drive/My Drive/Bangkit project/Dataset/coin-images.zip'\n",
        "\n",
        "# Unzip the dataset into folder\n",
        "zip_ref = zipfile.ZipFile(filepath, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt2d5YlhRQpK",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGaQrJvGRTG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define directories\n",
        "data_dir = \"/content/coins/data/\"\n",
        "\n",
        "train_dir = data_dir + \"train/\"\n",
        "validation_dir = data_dir + \"validation/\"\n",
        "test_dir = data_dir + \"test/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZoeHe2hJ-SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=360,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      brightness_range=[0.8,1.2],\n",
        "      horizontal_flip=False,\n",
        "      vertical_flip=False,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=360,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      brightness_range=[0.8,1.2],\n",
        "      horizontal_flip=False,\n",
        "      vertical_flip=False,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0BDiwC6MJcE",
        "colab_type": "code",
        "outputId": "4c9eea01-8554-4859-8c41-a8b19f0e4bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Read images from generators\n",
        "batch_size = 32\n",
        "image_width = 224\n",
        "image_height = 224\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "      test_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=1\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6413 images belonging to 211 classes.\n",
            "Found 844 images belonging to 211 classes.\n",
            "Found 844 images belonging to 211 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9QD8ft22wk_",
        "colab_type": "text"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX1T4tt0OrhX",
        "colab_type": "code",
        "outputId": "40cda91e-b827-46a3-ddf1-f56270a908cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load base model\n",
        "base_model = MobileNetV2(input_shape=(image_width, image_height, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "    # Add regularizer\n",
        "    l2_layer = l2(0.01)\n",
        "    if hasattr(layer, 'kernel'):\n",
        "        base_model.add_loss(lambda layer=layer: l2_layer(layer.kernel))\n",
        "\n",
        "for layer in base_model.layers[:10]:\n",
        "\t\tlayer.trainable = False\n",
        "\n",
        "# Custom top classifier for model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.55)(x)\n",
        "predictions = Dense(211, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.inputs, outputs=predictions)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
            "                                                                 block_2_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
            "                                                                 block_4_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
            "                                                                 block_5_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
            "                                                                 block_7_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
            "                                                                 block_8_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
            "                                                                 block_9_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
            "                                                                 block_11_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
            "                                                                 block_12_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
            "                                                                 block_14_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
            "                                                                 block_15_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          655872      global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 211)          108243      dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,022,099\n",
            "Trainable params: 2,986,163\n",
            "Non-trainable params: 35,936\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnhZ9bR-PiVb",
        "colab_type": "code",
        "outputId": "2795889a-30ed-41a5-af2f-0abec3f26510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Callback to reduce learning rate if no improvement in validation loss for certain number of epochs\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-8, verbose=1)\n",
        "\n",
        "# Callback to stop training if no improvement in validation loss for certain number of epochs\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# Callback to save best model weights per epoch\n",
        "weights_filepath = \"best_model_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=weights_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Nadam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=120,\n",
        "    steps_per_epoch=50,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1,\n",
        "    validation_steps=3,\n",
        "    callbacks=[reduce_lr, checkpoint]\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.5496 - accuracy: 0.0081\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.00000, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 602ms/step - loss: 5.5496 - accuracy: 0.0081 - val_loss: 5.5265 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.2693 - accuracy: 0.0156\n",
            "Epoch 00002: val_accuracy did not improve from 0.00000\n",
            "50/50 [==============================] - 29s 581ms/step - loss: 5.2693 - accuracy: 0.0156 - val_loss: 5.5111 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.1864 - accuracy: 0.0431\n",
            "Epoch 00003: val_accuracy improved from 0.00000 to 0.02083, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 5.1864 - accuracy: 0.0431 - val_loss: 5.3121 - val_accuracy: 0.0208 - lr: 1.0000e-04\n",
            "Epoch 4/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0249 - accuracy: 0.0625\n",
            "Epoch 00004: val_accuracy improved from 0.02083 to 0.04167, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 29s 589ms/step - loss: 5.0249 - accuracy: 0.0625 - val_loss: 5.2722 - val_accuracy: 0.0417 - lr: 1.0000e-04\n",
            "Epoch 5/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8135 - accuracy: 0.0975\n",
            "Epoch 00005: val_accuracy improved from 0.04167 to 0.06250, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 31s 628ms/step - loss: 4.8135 - accuracy: 0.0975 - val_loss: 5.0525 - val_accuracy: 0.0625 - lr: 1.0000e-04\n",
            "Epoch 6/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.6105 - accuracy: 0.1181\n",
            "Epoch 00006: val_accuracy did not improve from 0.06250\n",
            "50/50 [==============================] - 29s 578ms/step - loss: 4.6105 - accuracy: 0.1181 - val_loss: 5.1511 - val_accuracy: 0.0417 - lr: 1.0000e-04\n",
            "Epoch 7/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.3688 - accuracy: 0.1626\n",
            "Epoch 00007: val_accuracy improved from 0.06250 to 0.07292, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 4.3688 - accuracy: 0.1626 - val_loss: 4.8589 - val_accuracy: 0.0729 - lr: 1.0000e-04\n",
            "Epoch 8/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.1138 - accuracy: 0.1869\n",
            "Epoch 00008: val_accuracy improved from 0.07292 to 0.16667, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 593ms/step - loss: 4.1138 - accuracy: 0.1869 - val_loss: 4.4796 - val_accuracy: 0.1667 - lr: 1.0000e-04\n",
            "Epoch 9/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 3.8364 - accuracy: 0.2400\n",
            "Epoch 00009: val_accuracy did not improve from 0.16667\n",
            "50/50 [==============================] - 29s 581ms/step - loss: 3.8364 - accuracy: 0.2400 - val_loss: 4.6515 - val_accuracy: 0.0833 - lr: 1.0000e-04\n",
            "Epoch 10/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 3.6449 - accuracy: 0.2463\n",
            "Epoch 00010: val_accuracy did not improve from 0.16667\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 3.6449 - accuracy: 0.2463 - val_loss: 4.2777 - val_accuracy: 0.1146 - lr: 1.0000e-04\n",
            "Epoch 11/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 3.4246 - accuracy: 0.2912\n",
            "Epoch 00011: val_accuracy improved from 0.16667 to 0.18750, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 599ms/step - loss: 3.4246 - accuracy: 0.2912 - val_loss: 4.1122 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 12/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 3.1721 - accuracy: 0.3431\n",
            "Epoch 00012: val_accuracy did not improve from 0.18750\n",
            "50/50 [==============================] - 29s 581ms/step - loss: 3.1721 - accuracy: 0.3431 - val_loss: 3.9555 - val_accuracy: 0.1771 - lr: 1.0000e-04\n",
            "Epoch 13/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.9875 - accuracy: 0.3650\n",
            "Epoch 00013: val_accuracy improved from 0.18750 to 0.23958, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 595ms/step - loss: 2.9875 - accuracy: 0.3650 - val_loss: 3.7216 - val_accuracy: 0.2396 - lr: 1.0000e-04\n",
            "Epoch 14/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.8902 - accuracy: 0.3787\n",
            "Epoch 00014: val_accuracy did not improve from 0.23958\n",
            "50/50 [==============================] - 29s 584ms/step - loss: 2.8902 - accuracy: 0.3787 - val_loss: 3.7436 - val_accuracy: 0.2396 - lr: 1.0000e-04\n",
            "Epoch 15/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.6962 - accuracy: 0.4294\n",
            "Epoch 00015: val_accuracy did not improve from 0.23958\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 2.6962 - accuracy: 0.4294 - val_loss: 3.7601 - val_accuracy: 0.1667 - lr: 1.0000e-04\n",
            "Epoch 16/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.5321 - accuracy: 0.4412\n",
            "Epoch 00016: val_accuracy improved from 0.23958 to 0.25000, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 598ms/step - loss: 2.5321 - accuracy: 0.4412 - val_loss: 3.4118 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 17/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.3562 - accuracy: 0.4794\n",
            "Epoch 00017: val_accuracy did not improve from 0.25000\n",
            "50/50 [==============================] - 29s 589ms/step - loss: 2.3562 - accuracy: 0.4794 - val_loss: 3.5211 - val_accuracy: 0.2188 - lr: 1.0000e-04\n",
            "Epoch 18/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.2747 - accuracy: 0.5161\n",
            "Epoch 00018: val_accuracy improved from 0.25000 to 0.38542, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 2.2747 - accuracy: 0.5161 - val_loss: 2.9397 - val_accuracy: 0.3854 - lr: 1.0000e-04\n",
            "Epoch 19/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.1571 - accuracy: 0.5294\n",
            "Epoch 00019: val_accuracy did not improve from 0.38542\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 2.1571 - accuracy: 0.5294 - val_loss: 3.0254 - val_accuracy: 0.3646 - lr: 1.0000e-04\n",
            "Epoch 20/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.0438 - accuracy: 0.5437\n",
            "Epoch 00020: val_accuracy did not improve from 0.38542\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 2.0438 - accuracy: 0.5437 - val_loss: 2.8911 - val_accuracy: 0.3646 - lr: 1.0000e-04\n",
            "Epoch 21/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.9416 - accuracy: 0.5644\n",
            "Epoch 00021: val_accuracy did not improve from 0.38542\n",
            "50/50 [==============================] - 30s 594ms/step - loss: 1.9416 - accuracy: 0.5644 - val_loss: 2.8686 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 22/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.7700 - accuracy: 0.5987\n",
            "Epoch 00022: val_accuracy did not improve from 0.38542\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 1.7700 - accuracy: 0.5987 - val_loss: 2.5677 - val_accuracy: 0.3438 - lr: 1.0000e-04\n",
            "Epoch 23/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.7432 - accuracy: 0.5952\n",
            "Epoch 00023: val_accuracy did not improve from 0.38542\n",
            "50/50 [==============================] - 29s 579ms/step - loss: 1.7432 - accuracy: 0.5952 - val_loss: 2.7707 - val_accuracy: 0.3542 - lr: 1.0000e-04\n",
            "Epoch 24/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.7103 - accuracy: 0.6224\n",
            "Epoch 00024: val_accuracy improved from 0.38542 to 0.45833, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 593ms/step - loss: 1.7103 - accuracy: 0.6224 - val_loss: 2.3758 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
            "Epoch 25/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.6252 - accuracy: 0.6123\n",
            "Epoch 00025: val_accuracy improved from 0.45833 to 0.47917, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 29s 589ms/step - loss: 1.6252 - accuracy: 0.6123 - val_loss: 2.4313 - val_accuracy: 0.4792 - lr: 1.0000e-04\n",
            "Epoch 26/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.6070 - accuracy: 0.6249\n",
            "Epoch 00026: val_accuracy improved from 0.47917 to 0.53125, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 597ms/step - loss: 1.6070 - accuracy: 0.6249 - val_loss: 2.2986 - val_accuracy: 0.5312 - lr: 1.0000e-04\n",
            "Epoch 27/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.5002 - accuracy: 0.6525\n",
            "Epoch 00027: val_accuracy did not improve from 0.53125\n",
            "50/50 [==============================] - 30s 592ms/step - loss: 1.5002 - accuracy: 0.6525 - val_loss: 2.1719 - val_accuracy: 0.5104 - lr: 1.0000e-04\n",
            "Epoch 28/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.4805 - accuracy: 0.6519\n",
            "Epoch 00028: val_accuracy improved from 0.53125 to 0.61458, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 596ms/step - loss: 1.4805 - accuracy: 0.6519 - val_loss: 1.7779 - val_accuracy: 0.6146 - lr: 1.0000e-04\n",
            "Epoch 29/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.3628 - accuracy: 0.6612\n",
            "Epoch 00029: val_accuracy did not improve from 0.61458\n",
            "50/50 [==============================] - 29s 589ms/step - loss: 1.3628 - accuracy: 0.6612 - val_loss: 2.0627 - val_accuracy: 0.6146 - lr: 1.0000e-04\n",
            "Epoch 30/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.4250 - accuracy: 0.6641\n",
            "Epoch 00030: val_accuracy did not improve from 0.61458\n",
            "50/50 [==============================] - 29s 578ms/step - loss: 1.4250 - accuracy: 0.6641 - val_loss: 2.1691 - val_accuracy: 0.5312 - lr: 1.0000e-04\n",
            "Epoch 31/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.2929 - accuracy: 0.6950\n",
            "Epoch 00031: val_accuracy did not improve from 0.61458\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 1.2929 - accuracy: 0.6950 - val_loss: 2.2050 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
            "Epoch 32/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.2703 - accuracy: 0.7000\n",
            "Epoch 00032: val_accuracy did not improve from 0.61458\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 1.2703 - accuracy: 0.7000 - val_loss: 1.7200 - val_accuracy: 0.6042 - lr: 1.0000e-04\n",
            "Epoch 33/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.2111 - accuracy: 0.7106\n",
            "Epoch 00033: val_accuracy did not improve from 0.61458\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 1.2111 - accuracy: 0.7106 - val_loss: 1.9340 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 34/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1185 - accuracy: 0.7181\n",
            "Epoch 00034: val_accuracy did not improve from 0.61458\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 1.1185 - accuracy: 0.7181 - val_loss: 1.9336 - val_accuracy: 0.5938 - lr: 1.0000e-04\n",
            "Epoch 35/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1702 - accuracy: 0.7147\n",
            "Epoch 00035: val_accuracy improved from 0.61458 to 0.63542, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 1.1702 - accuracy: 0.7147 - val_loss: 1.6676 - val_accuracy: 0.6354 - lr: 1.0000e-04\n",
            "Epoch 36/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1360 - accuracy: 0.7231\n",
            "Epoch 00036: val_accuracy did not improve from 0.63542\n",
            "50/50 [==============================] - 29s 586ms/step - loss: 1.1360 - accuracy: 0.7231 - val_loss: 2.0081 - val_accuracy: 0.5312 - lr: 1.0000e-04\n",
            "Epoch 37/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0968 - accuracy: 0.7230\n",
            "Epoch 00037: val_accuracy improved from 0.63542 to 0.67708, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 593ms/step - loss: 1.0968 - accuracy: 0.7230 - val_loss: 1.4887 - val_accuracy: 0.6771 - lr: 1.0000e-04\n",
            "Epoch 38/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0583 - accuracy: 0.7356\n",
            "Epoch 00038: val_accuracy did not improve from 0.67708\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 1.0583 - accuracy: 0.7356 - val_loss: 1.6327 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 39/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0530 - accuracy: 0.7407\n",
            "Epoch 00039: val_accuracy did not improve from 0.67708\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 1.0530 - accuracy: 0.7407 - val_loss: 1.3531 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 40/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9880 - accuracy: 0.7487\n",
            "Epoch 00040: val_accuracy did not improve from 0.67708\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 0.9880 - accuracy: 0.7487 - val_loss: 1.7662 - val_accuracy: 0.6146 - lr: 1.0000e-04\n",
            "Epoch 41/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9612 - accuracy: 0.7688\n",
            "Epoch 00041: val_accuracy improved from 0.67708 to 0.78125, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 600ms/step - loss: 0.9612 - accuracy: 0.7688 - val_loss: 1.0694 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 42/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9038 - accuracy: 0.7731\n",
            "Epoch 00042: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 30s 596ms/step - loss: 0.9038 - accuracy: 0.7731 - val_loss: 1.2144 - val_accuracy: 0.6979 - lr: 1.0000e-04\n",
            "Epoch 43/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8896 - accuracy: 0.7856\n",
            "Epoch 00043: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 0.8896 - accuracy: 0.7856 - val_loss: 1.1503 - val_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 44/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8182 - accuracy: 0.8012\n",
            "Epoch 00044: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 0.8182 - accuracy: 0.8012 - val_loss: 1.0275 - val_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 45/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8858 - accuracy: 0.7681\n",
            "Epoch 00045: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 0.8858 - accuracy: 0.7681 - val_loss: 0.9318 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 46/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7754 - accuracy: 0.8081\n",
            "Epoch 00046: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 0.7754 - accuracy: 0.8081 - val_loss: 1.5546 - val_accuracy: 0.6458 - lr: 1.0000e-04\n",
            "Epoch 47/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8358 - accuracy: 0.7931\n",
            "Epoch 00047: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 29s 586ms/step - loss: 0.8358 - accuracy: 0.7931 - val_loss: 1.2923 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 48/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7674 - accuracy: 0.8144\n",
            "Epoch 00048: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 30s 591ms/step - loss: 0.7674 - accuracy: 0.8144 - val_loss: 1.0953 - val_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 49/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8183 - accuracy: 0.7925\n",
            "Epoch 00049: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 0.8183 - accuracy: 0.7925 - val_loss: 1.3147 - val_accuracy: 0.6771 - lr: 1.0000e-04\n",
            "Epoch 50/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7883 - accuracy: 0.7944\n",
            "Epoch 00050: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 0.7883 - accuracy: 0.7944 - val_loss: 1.4529 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 51/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7817 - accuracy: 0.7963\n",
            "Epoch 00051: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 0.7817 - accuracy: 0.7963 - val_loss: 1.2448 - val_accuracy: 0.7292 - lr: 1.0000e-04\n",
            "Epoch 52/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7562 - accuracy: 0.8075\n",
            "Epoch 00052: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 0.7562 - accuracy: 0.8075 - val_loss: 1.0243 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 53/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7196 - accuracy: 0.8075\n",
            "Epoch 00053: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 0.7196 - accuracy: 0.8075 - val_loss: 1.0517 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 54/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.8081\n",
            "Epoch 00054: val_accuracy improved from 0.78125 to 0.80208, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 598ms/step - loss: 0.6995 - accuracy: 0.8081 - val_loss: 1.0302 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 55/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.8387\n",
            "Epoch 00055: val_accuracy did not improve from 0.80208\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 0.6589 - accuracy: 0.8387 - val_loss: 0.8929 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 56/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6407 - accuracy: 0.8325\n",
            "Epoch 00056: val_accuracy improved from 0.80208 to 0.82292, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 602ms/step - loss: 0.6407 - accuracy: 0.8325 - val_loss: 0.7704 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 57/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6530 - accuracy: 0.8244\n",
            "Epoch 00057: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 0.6530 - accuracy: 0.8244 - val_loss: 0.8812 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 58/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5889 - accuracy: 0.8462\n",
            "Epoch 00058: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 584ms/step - loss: 0.5889 - accuracy: 0.8462 - val_loss: 1.0289 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 59/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.8275\n",
            "Epoch 00059: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 589ms/step - loss: 0.6564 - accuracy: 0.8275 - val_loss: 1.0040 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 60/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.8292\n",
            "Epoch 00060: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 0.6356 - accuracy: 0.8292 - val_loss: 1.0362 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 61/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.8494\n",
            "Epoch 00061: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 30s 597ms/step - loss: 0.5852 - accuracy: 0.8494 - val_loss: 0.8797 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 62/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.8494\n",
            "Epoch 00062: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 30s 594ms/step - loss: 0.5745 - accuracy: 0.8494 - val_loss: 1.1593 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 63/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.8381\n",
            "Epoch 00063: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 0.5852 - accuracy: 0.8381 - val_loss: 1.5001 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 64/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.8450\n",
            "Epoch 00064: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 30s 592ms/step - loss: 0.5915 - accuracy: 0.8450 - val_loss: 0.7392 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 65/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.8469\n",
            "Epoch 00065: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 579ms/step - loss: 0.5785 - accuracy: 0.8469 - val_loss: 0.8607 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 66/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.8644\n",
            "Epoch 00066: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 0.5184 - accuracy: 0.8644 - val_loss: 1.0077 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 67/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5554 - accuracy: 0.8481\n",
            "Epoch 00067: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 0.5554 - accuracy: 0.8481 - val_loss: 1.2031 - val_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 68/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.8596\n",
            "Epoch 00068: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 583ms/step - loss: 0.5167 - accuracy: 0.8596 - val_loss: 1.4193 - val_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 69/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.8672\n",
            "Epoch 00069: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 0.5185 - accuracy: 0.8672 - val_loss: 0.6676 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 70/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.8737\n",
            "Epoch 00070: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 0.4617 - accuracy: 0.8737 - val_loss: 0.8832 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 71/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4956 - accuracy: 0.8612\n",
            "Epoch 00071: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 586ms/step - loss: 0.4956 - accuracy: 0.8612 - val_loss: 1.0990 - val_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 72/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.8813\n",
            "Epoch 00072: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 589ms/step - loss: 0.4571 - accuracy: 0.8813 - val_loss: 0.9909 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 73/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.8675\n",
            "Epoch 00073: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 30s 591ms/step - loss: 0.4480 - accuracy: 0.8675 - val_loss: 0.8088 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 74/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.8678\n",
            "Epoch 00074: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 0.4867 - accuracy: 0.8678 - val_loss: 0.7818 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 75/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.8825\n",
            "Epoch 00075: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 0.4343 - accuracy: 0.8825 - val_loss: 1.0342 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 76/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.8775\n",
            "Epoch 00076: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 0.4472 - accuracy: 0.8775 - val_loss: 0.7848 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 77/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.8788\n",
            "Epoch 00077: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 589ms/step - loss: 0.4429 - accuracy: 0.8788 - val_loss: 0.8818 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 78/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8863\n",
            "Epoch 00078: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 0.4272 - accuracy: 0.8863 - val_loss: 0.9819 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 79/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8798\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 577ms/step - loss: 0.4135 - accuracy: 0.8798 - val_loss: 1.2036 - val_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 80/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.8963\n",
            "Epoch 00080: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 582ms/step - loss: 0.3817 - accuracy: 0.8963 - val_loss: 0.9571 - val_accuracy: 0.7604 - lr: 1.0000e-05\n",
            "Epoch 81/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3499 - accuracy: 0.9056\n",
            "Epoch 00081: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 584ms/step - loss: 0.3499 - accuracy: 0.9056 - val_loss: 0.8910 - val_accuracy: 0.7917 - lr: 1.0000e-05\n",
            "Epoch 82/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3713 - accuracy: 0.8963\n",
            "Epoch 00082: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 581ms/step - loss: 0.3713 - accuracy: 0.8963 - val_loss: 0.8676 - val_accuracy: 0.8021 - lr: 1.0000e-05\n",
            "Epoch 83/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.9025\n",
            "Epoch 00083: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 0.3436 - accuracy: 0.9025 - val_loss: 1.2699 - val_accuracy: 0.8021 - lr: 1.0000e-05\n",
            "Epoch 84/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.9056\n",
            "Epoch 00084: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 0.3620 - accuracy: 0.9056 - val_loss: 1.1977 - val_accuracy: 0.7188 - lr: 1.0000e-05\n",
            "Epoch 85/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.8969\n",
            "Epoch 00085: val_accuracy improved from 0.82292 to 0.87500, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 30s 596ms/step - loss: 0.3545 - accuracy: 0.8969 - val_loss: 0.5900 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 86/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.8994\n",
            "Epoch 00086: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 0.3751 - accuracy: 0.8994 - val_loss: 1.0324 - val_accuracy: 0.7917 - lr: 1.0000e-05\n",
            "Epoch 87/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3180 - accuracy: 0.9131\n",
            "Epoch 00087: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 594ms/step - loss: 0.3180 - accuracy: 0.9131 - val_loss: 0.7674 - val_accuracy: 0.7917 - lr: 1.0000e-05\n",
            "Epoch 88/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3578 - accuracy: 0.8981\n",
            "Epoch 00088: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 593ms/step - loss: 0.3578 - accuracy: 0.8981 - val_loss: 0.9454 - val_accuracy: 0.7812 - lr: 1.0000e-05\n",
            "Epoch 89/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.9038\n",
            "Epoch 00089: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 597ms/step - loss: 0.3516 - accuracy: 0.9038 - val_loss: 0.5620 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 90/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3368 - accuracy: 0.9056\n",
            "Epoch 00090: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 0.3368 - accuracy: 0.9056 - val_loss: 1.0770 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 91/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.9254\n",
            "Epoch 00091: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 0.3046 - accuracy: 0.9254 - val_loss: 0.8279 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 92/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3252 - accuracy: 0.9019\n",
            "Epoch 00092: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 595ms/step - loss: 0.3252 - accuracy: 0.9019 - val_loss: 0.8505 - val_accuracy: 0.8229 - lr: 1.0000e-05\n",
            "Epoch 93/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.9006\n",
            "Epoch 00093: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 598ms/step - loss: 0.3446 - accuracy: 0.9006 - val_loss: 0.5943 - val_accuracy: 0.8438 - lr: 1.0000e-05\n",
            "Epoch 94/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.9064\n",
            "Epoch 00094: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 29s 584ms/step - loss: 0.3222 - accuracy: 0.9064 - val_loss: 0.8961 - val_accuracy: 0.7708 - lr: 1.0000e-05\n",
            "Epoch 95/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.9100\n",
            "Epoch 00095: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 0.3240 - accuracy: 0.9100 - val_loss: 0.8633 - val_accuracy: 0.8229 - lr: 1.0000e-05\n",
            "Epoch 96/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.9171\n",
            "Epoch 00096: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 0.3084 - accuracy: 0.9171 - val_loss: 0.8697 - val_accuracy: 0.7708 - lr: 1.0000e-05\n",
            "Epoch 97/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.9144\n",
            "Epoch 00097: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 594ms/step - loss: 0.3139 - accuracy: 0.9144 - val_loss: 0.6423 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 98/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9156\n",
            "Epoch 00098: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 598ms/step - loss: 0.3169 - accuracy: 0.9156 - val_loss: 0.8236 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 99/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.9144\n",
            "Epoch 00099: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 601ms/step - loss: 0.3225 - accuracy: 0.9144 - val_loss: 0.5576 - val_accuracy: 0.8646 - lr: 1.0000e-05\n",
            "Epoch 100/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3253 - accuracy: 0.9094\n",
            "Epoch 00100: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 598ms/step - loss: 0.3253 - accuracy: 0.9094 - val_loss: 1.2203 - val_accuracy: 0.7292 - lr: 1.0000e-05\n",
            "Epoch 101/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.9131\n",
            "Epoch 00101: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 600ms/step - loss: 0.3240 - accuracy: 0.9131 - val_loss: 0.9938 - val_accuracy: 0.7708 - lr: 1.0000e-05\n",
            "Epoch 102/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.9125\n",
            "Epoch 00102: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 594ms/step - loss: 0.3137 - accuracy: 0.9125 - val_loss: 0.5913 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 103/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.9250\n",
            "Epoch 00103: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 603ms/step - loss: 0.2887 - accuracy: 0.9250 - val_loss: 0.8402 - val_accuracy: 0.7708 - lr: 1.0000e-05\n",
            "Epoch 104/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.9178\n",
            "Epoch 00104: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 599ms/step - loss: 0.3065 - accuracy: 0.9178 - val_loss: 0.8546 - val_accuracy: 0.7708 - lr: 1.0000e-05\n",
            "Epoch 105/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.9287\n",
            "Epoch 00105: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 601ms/step - loss: 0.2749 - accuracy: 0.9287 - val_loss: 0.7956 - val_accuracy: 0.8229 - lr: 1.0000e-05\n",
            "Epoch 106/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9106\n",
            "Epoch 00106: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 602ms/step - loss: 0.3169 - accuracy: 0.9106 - val_loss: 1.0444 - val_accuracy: 0.7708 - lr: 1.0000e-05\n",
            "Epoch 107/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3194 - accuracy: 0.9108\n",
            "Epoch 00107: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 593ms/step - loss: 0.3194 - accuracy: 0.9108 - val_loss: 0.6472 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 108/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9281\n",
            "Epoch 00108: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 600ms/step - loss: 0.2514 - accuracy: 0.9281 - val_loss: 0.6488 - val_accuracy: 0.7917 - lr: 1.0000e-05\n",
            "Epoch 109/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.9150\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 601ms/step - loss: 0.3012 - accuracy: 0.9150 - val_loss: 0.9606 - val_accuracy: 0.7812 - lr: 1.0000e-05\n",
            "Epoch 110/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.9254\n",
            "Epoch 00110: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 591ms/step - loss: 0.2879 - accuracy: 0.9254 - val_loss: 0.9724 - val_accuracy: 0.7812 - lr: 1.0000e-06\n",
            "Epoch 111/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.9175\n",
            "Epoch 00111: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 600ms/step - loss: 0.2938 - accuracy: 0.9175 - val_loss: 0.8536 - val_accuracy: 0.8333 - lr: 1.0000e-06\n",
            "Epoch 112/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.9294\n",
            "Epoch 00112: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 603ms/step - loss: 0.2744 - accuracy: 0.9294 - val_loss: 0.5642 - val_accuracy: 0.8542 - lr: 1.0000e-06\n",
            "Epoch 113/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.9106\n",
            "Epoch 00113: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 598ms/step - loss: 0.2992 - accuracy: 0.9106 - val_loss: 0.8986 - val_accuracy: 0.7917 - lr: 1.0000e-06\n",
            "Epoch 114/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.9197\n",
            "Epoch 00114: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 595ms/step - loss: 0.2812 - accuracy: 0.9197 - val_loss: 1.2077 - val_accuracy: 0.7708 - lr: 1.0000e-06\n",
            "Epoch 115/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9256\n",
            "Epoch 00115: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 602ms/step - loss: 0.2745 - accuracy: 0.9256 - val_loss: 0.9168 - val_accuracy: 0.7917 - lr: 1.0000e-06\n",
            "Epoch 116/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.9156\n",
            "Epoch 00116: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 605ms/step - loss: 0.3091 - accuracy: 0.9156 - val_loss: 0.8047 - val_accuracy: 0.8021 - lr: 1.0000e-06\n",
            "Epoch 117/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.9156\n",
            "Epoch 00117: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 602ms/step - loss: 0.3087 - accuracy: 0.9156 - val_loss: 0.9956 - val_accuracy: 0.7812 - lr: 1.0000e-06\n",
            "Epoch 118/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.9212\n",
            "Epoch 00118: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 593ms/step - loss: 0.3028 - accuracy: 0.9212 - val_loss: 0.9596 - val_accuracy: 0.8333 - lr: 1.0000e-06\n",
            "Epoch 119/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.9175\n",
            "Epoch 00119: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 0.2867 - accuracy: 0.9175 - val_loss: 1.1357 - val_accuracy: 0.7812 - lr: 1.0000e-06\n",
            "Epoch 120/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.9262\n",
            "Epoch 00120: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 30s 594ms/step - loss: 0.2876 - accuracy: 0.9262 - val_loss: 0.8605 - val_accuracy: 0.8125 - lr: 1.0000e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwZTPuGY8rWm",
        "colab_type": "code",
        "outputId": "6b8a0e1f-2f84-4133-85a6-54427771b4e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Visualise accuracy history\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Visualise loss history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIvbXL32hN48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "model.save(\"mobilenet_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCXE1Nm45huL",
        "colab_type": "code",
        "outputId": "6fe7e415-dcf1-4638-b7cc-713e2c8fefd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Evaluate model\n",
        "train_score = model.evaluate(train_generator, verbose=1)\n",
        "print(\"Training loss: \", train_score[0])\n",
        "print(\"Training accuracy: \", train_score[1])\n",
        "\n",
        "validation_score = model.evaluate(validation_generator, verbose=1)\n",
        "print(\"Validation loss: \", validation_score[0])\n",
        "print(\"Validation accuracy: \", validation_score[1])\n",
        "\n",
        "test_score = model.evaluate(test_generator, verbose=1)\n",
        "print(\"Testing loss: \", test_score[0])\n",
        "print(\"Testing accuracy: \", test_score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201/201 [==============================] - 102s 508ms/step - loss: 0.0982 - accuracy: 0.9715\n",
            "Training loss:  0.09816599637269974\n",
            "Training accuracy:  0.971464216709137\n",
            "27/27 [==============================] - 13s 485ms/step - loss: 0.8529 - accuracy: 0.8045\n",
            "Validation loss:  0.8528911471366882\n",
            "Validation accuracy:  0.8045023679733276\n",
            "844/844 [==============================] - 6s 8ms/step - loss: 0.6531 - accuracy: 0.8365\n",
            "Testing loss:  0.6530923843383789\n",
            "Testing accuracy:  0.8364928960800171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ztC3j9zTRyES",
        "colab": {}
      },
      "source": [
        "model_best_weights = model\n",
        "\n",
        "# Load best model weights\n",
        "model_best_weights.load_weights(weights_filepath)\n",
        "\n",
        "# Save model\n",
        "model_best_weights.save(\"mobilenet_model_best_weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ed6NgxyJR_Ce",
        "outputId": "1b0d4a83-6fe8-4d9d-8c1d-96d21996867c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Evaluate model\n",
        "train_score = model_best_weights.evaluate(train_generator, verbose=1)\n",
        "print(\"Training loss: \", train_score[0])\n",
        "print(\"Training accuracy: \", train_score[1])\n",
        "\n",
        "validation_score = model_best_weights.evaluate(validation_generator, verbose=1)\n",
        "print(\"Validation loss: \", validation_score[0])\n",
        "print(\"Validation accuracy: \", validation_score[1])\n",
        "\n",
        "test_score = model_best_weights.evaluate(test_generator, verbose=1)\n",
        "print(\"Testing loss: \", test_score[0])\n",
        "print(\"Testing accuracy: \", test_score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201/201 [==============================] - 102s 507ms/step - loss: 0.1457 - accuracy: 0.9607\n",
            "Training loss:  0.1456790268421173\n",
            "Training accuracy:  0.9607048034667969\n",
            "27/27 [==============================] - 13s 475ms/step - loss: 0.8649 - accuracy: 0.7974\n",
            "Validation loss:  0.8649319410324097\n",
            "Validation accuracy:  0.7973933815956116\n",
            "844/844 [==============================] - 6s 8ms/step - loss: 0.6799 - accuracy: 0.8246\n",
            "Testing loss:  0.6798509955406189\n",
            "Testing accuracy:  0.8246445655822754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PJ6NpZE8AzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict test images\n",
        "predictions = []\n",
        "\n",
        "for filename in test_generator.filenames:\n",
        "    img = load_img(test_dir+filename, target_size=(image_width, image_height))\n",
        "    img = img_to_array(img)/255\n",
        "    img_expand = np.expand_dims(img, axis=0)\n",
        "    predictions.append(model.predict(img_expand)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhHvvZGaHKQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get index of largest probability\n",
        "predicted_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get coin directory name from index \n",
        "directories = dict((v, k) for k, v in train_generator.class_indices.items())\n",
        "predicted_dir = [directories.get(k) for k in predicted_indices]\n",
        "\n",
        "# Get label name from coin directory name\n",
        "with open(data_dir + 'cat_to_name.json', 'r') as json_file:\n",
        "    labels = json.load(json_file)\n",
        "predicted_labels = [labels.get(str(k)) for k in predicted_dir]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4DLt4o3H78s",
        "colab_type": "code",
        "outputId": "ef4df53f-09d0-4a33-b39c-a8bbf719d35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Save predicted labels as CSV file\n",
        "filenames = test_generator.filenames\n",
        "results = pd.DataFrame({\"Filename\": filenames, \"Predictions\": predicted_labels})\n",
        "results.to_csv(\"mobilenet_results.csv\", index=False)\n",
        "results.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/021__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/022__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/027__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/036__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10/005__5 Centavos_brazil.jpg</td>\n",
              "      <td>5 Centavos,Brazilian Real,brazil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Filename                         Predictions\n",
              "0    1/021__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "1    1/022__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "2    1/027__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "3    1/036__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "4  10/005__5 Centavos_brazil.jpg    5 Centavos,Brazilian Real,brazil"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZlj71Kl_2WO",
        "colab_type": "text"
      },
      "source": [
        "# **Convert to TFLite**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVWQuD08_1hc",
        "colab_type": "code",
        "outputId": "0649aa1a-b86c-4726-ceb3-df0c0da75207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "open(\"mobilenet_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3054968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX-yMWB34O4C",
        "colab_type": "text"
      },
      "source": [
        "# **Copy model to Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcyZNaSi4bkN",
        "colab_type": "code",
        "outputId": "752e99d7-642e-4b53-cf74-22a0093c8f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp mobilenet_model.h5 \"/content/drive/My Drive/Bangkit project/models\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}